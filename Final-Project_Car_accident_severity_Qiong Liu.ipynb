{"cells":[{"metadata":{},"cell_type":"markdown","source":["<h2 align=center><font size = 5>Seattle Car Collision Severity Analysis</font></h2>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import the library\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["filepath = \"/Users/John/Documents/GitHub/Related_Data/Data-Collisions.csv\" \n","df_whole = pd.read_csv(filepath)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_whole.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_whole.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# check the data set summary, only 23 attributes are useful, so create a new dataframe\n","# 'PERSONCOUNT', 'PEDCOUNT', 'PEDCYLCOUNT', 'VEHCOUNT','SDOT_COLCODE', 'SDOT_COLDESC',\n","df = df_whole[['SEVERITYCODE','SEVERITYDESC', 'ADDRTYPE', 'INCDATE','INCDTTM', 'JUNCTIONTYPE', 'INATTENTIONIND', 'UNDERINFL', 'WEATHER', 'ROADCOND', 'LIGHTCOND','SPEEDING', 'HITPARKEDCAR']]\n","\n","df_map = df_whole[['SEVERITYCODE','X', 'Y']]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["df.info()"]},{"source":["## Identify and handle missing values"],"cell_type":"markdown","metadata":{}},{"source":["### identify missing data \n","Convert \"?\" to NaN\n","In the car dataset, missing data comes with the question mark \"?\". We replace \"?\" with NaN (Not a Number), which is Python's default missing value marker, for reasons of computational speed and convenience. Here we use the function:\n",".replace(A, B, inplace = True) "],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# replace \"?\" to NaN\n","df.replace(\"?\", np.nan, inplace = True)"]},{"source":["# Evaluating for Missing Data\n","missing_data = df.isnull()\n","for column in missing_data.columns.values.tolist():\n","    print(column)\n","    print (missing_data[column].value_counts())\n","    print(\"\")"],"cell_type":"code","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"source":["#### Replace missing value by frequency:"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# which values are present in a particular column, we can use the \".value_counts()\" method: df['num-of-doors'].value_counts()\n","# use the \".idxmax()\" method to calculate for us the most common type automatically: df['ADDRTYPE'].value_counts().idxmax()\n","#replace the missing 'num-of-doors' values by the most frequent \n","df[\"ADDRTYPE\"].replace(np.nan, df['ADDRTYPE'].value_counts().idxmax(), inplace=True)\n","df['ADDRTYPE'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"JUNCTIONTYPE\"].replace(np.nan, df['JUNCTIONTYPE'].value_counts().idxmax(), inplace=True)\n","df[\"JUNCTIONTYPE\"].replace(\"Unknown\", df['JUNCTIONTYPE'].value_counts().idxmax(), inplace=True)\n","df[\"JUNCTIONTYPE\"].replace(\"Ramp Junction\", 'RampDriveway', inplace=True)\n","df[\"JUNCTIONTYPE\"].replace(\"Driveway Junction\", 'RampDriveway', inplace=True)\n","df[\"JUNCTIONTYPE\"].replace(\"At Intersection (intersection related)\", 'At-Intersection', inplace=True)\n","df[\"JUNCTIONTYPE\"].replace(\"At Intersection (but not related to intersection)\", 'At-Intersection', inplace=True)\n","df['JUNCTIONTYPE'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# data_clean['UNDERINFL'] = data_clean['UNDERINFL'].map({'N': 0, '0': 0, 'Y': 1, '1': 1})\n","df[\"UNDERINFL\"].replace(np.nan, df['UNDERINFL'].value_counts().idxmax(), inplace=True)\n","df[\"UNDERINFL\"].replace(\"0\", \"N\", inplace=True)\n","df[\"UNDERINFL\"].replace(\"1\", \"Y\", inplace=True)\n","df['UNDERINFL'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"WEATHER\"].replace(np.nan, df['WEATHER'].value_counts().idxmax(), inplace=True)\n","df[\"WEATHER\"].replace(\"Other\",\"Unknown\",inplace=True)\n","df[\"WEATHER\"].replace(\"Partly Cloudy\",\"Overcast\",inplace=True)\n","df[\"WEATHER\"].replace(\"Raining\",\"RainSnow\",inplace=True)\n","df[\"WEATHER\"].replace(\"Snowing\",\"RainSnow\",inplace=True)\n","df[\"WEATHER\"].replace(\"Sleet/Hail/Freezing Rain\",\"RainSnow\",inplace=True)\n","df[\"WEATHER\"].replace(\"Fog/Smog/Smoke\",\"RainSnow\",inplace=True)\n","df[\"WEATHER\"].replace(\"Blowing Sand/Dirt\",\"RainSnow\",inplace=True)\n","df[\"WEATHER\"].replace(\"Severe Crosswind\",\"RainSnow\",inplace=True)\n","df['WEATHER'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"ROADCOND\"].replace(np.nan, df['ROADCOND'].value_counts().idxmax(), inplace=True)\n","df[\"ROADCOND\"].replace(\"Ice\", \"IceOilWaterSnow\", inplace=True)\n","df[\"ROADCOND\"].replace(\"Standing Water\", \"IceOilWaterSnow\", inplace=True)\n","df[\"ROADCOND\"].replace(\"Oil\", \"IceOilWaterSnow\", inplace=True)\n","df[\"ROADCOND\"].replace(\"Snow/Slush\", \"IceOilWaterSnow\", inplace=True)\n","df[\"ROADCOND\"].replace(\"Other\", \"Unknown\", inplace=True)\n","df[\"ROADCOND\"].replace(\"Sand/Mud/Dirt\", \"IceOilWaterSnow\", inplace=True)\n","df['ROADCOND'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"LIGHTCOND\"].replace(np.nan, df['LIGHTCOND'].value_counts().idxmax(), inplace=True)\n","df[\"LIGHTCOND\"].replace(\"Dark - No Street Lights\", \"Dark-No-Light\", inplace=True)\n","df[\"LIGHTCOND\"].replace(\"Dark - Street Lights Off\", \"Dark-No-Light\", inplace=True)\n","df[\"LIGHTCOND\"].replace(\"Dark - Unknown Lighting\", \"Dark-No-Light\", inplace=True)\n","df[\"LIGHTCOND\"].replace(\"Dark - Street Lights On\", \"Dark-With-Light\", inplace=True)\n","df[\"LIGHTCOND\"].replace(\"Other\", \"Unknown\", inplace=True)\n","df[\"LIGHTCOND\"].replace(\"Dusk\", \"DuskDawn\", inplace=True)\n","df[\"LIGHTCOND\"].replace(\"Dawn\", \"DuskDawn\", inplace=True)\n","df['LIGHTCOND'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# only has Y, so all the other value should be N\n","df[\"INATTENTIONIND\"].replace(np.nan, \"N\", inplace=True)\n","df[\"INATTENTIONIND\"].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"SPEEDING\"].replace(np.nan, \"N\", inplace=True)\n","df[\"SPEEDING\"].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"SEVERITYDESC\"].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["df.info()"]},{"source":["#### Replace missing value by mean:"],"cell_type":"markdown","metadata":{}},{"source":["#### Drop the whole row:"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# simply drop whole row with NaN in \"X\" and \"Y\" column\n","df_map.dropna(subset=[\"X\"], axis=0, inplace=True)\n","df_map.shape"]},{"source":["#### Correct data format\n","\n","Convert data types to proper format"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### Convert to date time object\n","df['INCDTTM'] = pd.to_datetime(df['INCDTTM'])\n","df['INCDATE'] = pd.to_datetime(df['INCDATE'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# double check\n","df.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# covert datetime to weekday and hours\n","df['hourofday'] = df['INCDTTM'].dt.hour\n","df['dayofweek'] = df['INCDTTM'].dt.dayofweek\n","df.head(5)"]},{"source":["#### data_standardization"],"cell_type":"markdown","metadata":{}},{"source":["#### Data Normalization"],"cell_type":"markdown","metadata":{}},{"source":["#### Binning\n","\n","transforming continuous numerical variables into discrete categorical 'bins', for grouped analysis."],"cell_type":"markdown","metadata":{}},{"source":["#### Indicator variable (or dummy variable)"],"cell_type":"markdown","metadata":{}},{"source":["### Analyzing Individual Feature Patterns using Visualization"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from matplotlib.pyplot import show\n","import seaborn as sns\n","\n","plt.figure(figsize=(10,5))\n","sns.set(style=\"darkgrid\")\n","#titanic = sns.load_dataset(\"titanic\")\n","total = float(len(df)) # one person per row \n","#ax = sns.barplot(x=\"class\", hue=\"who\", data=titanic)\n","ax = sns.countplot(x=\"JUNCTIONTYPE\", hue=\"SEVERITYDESC\", data=df) # for Seaborn version 0.7 and more\n","for p in ax.patches:\n","    height = p.get_height()\n","    ax.text(p.get_x()+p.get_width()/2.,\n","            height + 3,\n","            '{:.2%}'.format(height/total),\n","            ha=\"center\") \n","show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from matplotlib.pyplot import show\n","import seaborn as sns\n","\n","plt.figure(figsize=(10,5))\n","sns.set(style=\"darkgrid\")\n","#titanic = sns.load_dataset(\"titanic\")\n","total = float(len(df)) # one person per row \n","#ax = sns.barplot(x=\"class\", hue=\"who\", data=titanic)\n","ax = sns.countplot(x=\"ADDRTYPE\", hue=\"SEVERITYDESC\", data=df) # for Seaborn version 0.7 and more\n","for p in ax.patches:\n","    height = p.get_height()\n","    ax.text(p.get_x()+p.get_width()/2.,\n","            height + 3,\n","            '{:.2%}'.format(height/total),\n","            ha=\"center\") \n","show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from matplotlib.pyplot import show\n","import seaborn as sns\n","\n","plt.figure(figsize=(15,7))\n","sns.set(style=\"darkgrid\")\n","#titanic = sns.load_dataset(\"titanic\")\n","total = float(len(df)) # one person per row \n","#ax = sns.barplot(x=\"class\", hue=\"who\", data=titanic)\n","ax = sns.countplot(x=\"dayofweek\", hue=\"SEVERITYDESC\", data=df) \n","# Monday=0, Sunday=6\n","for p in ax.patches:\n","    height = p.get_height()\n","    ax.text(p.get_x()+p.get_width()/2.,\n","            height + 3,\n","            '{:1.2%}'.format(height/total),\n","            ha=\"center\") \n","show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\n","\n","plt.figure(figsize=(15,7))\n","sns.set(style=\"darkgrid\")\n","#titanic = sns.load_dataset(\"titanic\")\n","total = float(len(df)) # one person per row \n","#ax = sns.barplot(x=\"class\", hue=\"who\", data=titanic)\n","ax = sns.countplot(x=\"weekend\", hue=\"SEVERITYDESC\", data=df) \n","# Monday=0, Sunday=6\n","for p in ax.patches:\n","    height = p.get_height()\n","    ax.text(p.get_x()+p.get_width()/2.,\n","            height + 3,\n","            '{:1.2%}'.format(height/total),\n","            ha=\"center\") \n","show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from matplotlib.pyplot import show\n","import seaborn as sns\n","\n","plt.figure(figsize=(10,5))\n","sns.set(style=\"darkgrid\")\n","#titanic = sns.load_dataset(\"titanic\")\n","total = float(len(df)) # one person per row \n","#ax = sns.barplot(x=\"class\", hue=\"who\", data=titanic)\n","ax = sns.countplot(x=\"INATTENTIONIND\", hue=\"SEVERITYDESC\", data=df) # for Seaborn version 0.7 and more\n","for p in ax.patches:\n","    height = p.get_height()\n","    ax.text(p.get_x()+p.get_width()/2.,\n","            height + 3,\n","            '{:1.2%}'.format(height/total),\n","            ha=\"center\") \n","show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from matplotlib.pyplot import show\n","import seaborn as sns\n","\n","plt.figure(figsize=(15,8))\n","sns.set(style=\"darkgrid\")\n","#titanic = sns.load_dataset(\"titanic\")\n","total = float(len(df)) # one person per row \n","#ax = sns.barplot(x=\"class\", hue=\"who\", data=titanic)\n","ax = sns.countplot(x=\"hourofday\", hue=\"SEVERITYDESC\", data=df) # for Seaborn version 0.7 and more\n","for p in ax.patches:\n","    height = p.get_height()\n","    ax.text(p.get_x()+p.get_width()/2.,\n","            height + 3,\n","            '{:1.2%}'.format(height/total),\n","            ha=\"center\") \n","show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# High risk =1, relative ration > 3; Midum Risk = 0, for 2 > relative ration < 3; \n","df['RiskTime'] = df['hourofday'].apply(lambda x: \"Low\" if x in (1,2,3,4) else (\"Medium\" if x in (5,6,7,8,9,10,11,12,13,14,15,16) else \"High\"))\n","\n","from matplotlib.pyplot import show\n","import seaborn as sns\n","\n","plt.figure(figsize=(10,5))\n","sns.set(style=\"darkgrid\")\n","#titanic = sns.load_dataset(\"titanic\")\n","total = float(len(df)) # one person per row \n","#ax = sns.barplot(x=\"class\", hue=\"who\", data=titanic)\n","ax = sns.countplot(x=\"RiskTime\", hue=\"SEVERITYDESC\", data=df) # for Seaborn version 0.7 and more\n","for p in ax.patches:\n","    height = p.get_height()\n","    ax.text(p.get_x()+p.get_width()/2.,\n","            height + 3,\n","            '{:1.2%}'.format(height/total),\n","            ha=\"center\") \n","show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from matplotlib.pyplot import show\n","import seaborn as sns\n","\n","plt.figure(figsize=(10,5))\n","sns.set(style=\"darkgrid\")\n","#titanic = sns.load_dataset(\"titanic\")\n","total = float(len(df)) # one person per row \n","#ax = sns.barplot(x=\"class\", hue=\"who\", data=titanic)\n","ax = sns.countplot(x=\"UNDERINFL\", hue=\"SEVERITYDESC\", data=df) # for Seaborn version 0.7 and more\n","for p in ax.patches:\n","    height = p.get_height()\n","    ax.text(p.get_x()+p.get_width()/2.,\n","            height + 3,\n","            '{:1.2%}'.format(height/total),\n","            ha=\"center\") \n","show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from matplotlib.pyplot import show\n","import seaborn as sns\n","\n","plt.figure(figsize=(15,8))\n","sns.set(style=\"darkgrid\")\n","#titanic = sns.load_dataset(\"titanic\")\n","total = float(len(df)) # one person per row \n","#ax = sns.barplot(x=\"class\", hue=\"who\", data=titanic)\n","ax = sns.countplot(x=\"WEATHER\", hue=\"SEVERITYDESC\", data=df) # for Seaborn version 0.7 and more\n","for p in ax.patches:\n","    height = p.get_height()\n","    ax.text(p.get_x()+p.get_width()/2.,\n","            height + 3,\n","            '{:1.2%}'.format(height/total),\n","            ha=\"center\") \n","show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from matplotlib.pyplot import show\n","import seaborn as sns\n","\n","plt.figure(figsize=(15,8))\n","sns.set(style=\"darkgrid\")\n","#titanic = sns.load_dataset(\"titanic\")\n","total = float(len(df)) # one person per row \n","#ax = sns.barplot(x=\"class\", hue=\"who\", data=titanic)\n","ax = sns.countplot(x=\"ROADCOND\", hue=\"SEVERITYDESC\", data=df) # for Seaborn version 0.7 and more\n","for p in ax.patches:\n","    height = p.get_height()\n","    ax.text(p.get_x()+p.get_width()/2.,\n","            height + 3,\n","            '{:1.2%}'.format(height/total),\n","            ha=\"center\") \n","show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from matplotlib.pyplot import show\n","import seaborn as sns\n","\n","plt.figure(figsize=(15,8))\n","sns.set(style=\"darkgrid\")\n","#titanic = sns.load_dataset(\"titanic\")\n","total = float(len(df)) # one person per row \n","#ax = sns.barplot(x=\"class\", hue=\"who\", data=titanic)\n","ax = sns.countplot(x=\"LIGHTCOND\", hue=\"SEVERITYDESC\", data=df) # for Seaborn version 0.7 and more\n","for p in ax.patches:\n","    height = p.get_height()\n","    ax.text(p.get_x()+p.get_width()/2.,\n","            height + 3,\n","            '{:1.2%}'.format(height/total),\n","            ha=\"center\") \n","show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from matplotlib.pyplot import show\n","import seaborn as sns\n","\n","plt.figure(figsize=(10,5))\n","sns.set(style=\"darkgrid\")\n","#titanic = sns.load_dataset(\"titanic\")\n","total = float(len(df)) # one person per row \n","#ax = sns.barplot(x=\"class\", hue=\"who\", data=titanic)\n","ax = sns.countplot(x=\"SPEEDING\", hue=\"SEVERITYDESC\", data=df) # for Seaborn version 0.7 and more\n","for p in ax.patches:\n","    height = p.get_height()\n","    ax.text(p.get_x()+p.get_width()/2.,\n","            height + 3,\n","            '{:1.2%}'.format(height/total),\n","            ha=\"center\") \n","show()"]},{"source":["#### Continuous numerical variables and linear relationship"],"cell_type":"markdown","metadata":{}},{"source":["#### Categorical variables using boxplot"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline \n","\n","#sns.boxplot(x=\"hourofday\", y=\"SEVERITYCODE\", data=df)"]},{"source":["### Descriptive Statistical Analysis"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# The default setting of \"describe\" skips variables of type object. \n","df.describe(include=['object'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['SEVERITYCODE'].value_counts()"]},{"source":["#### Grouping\n","\n","The \"groupby\" method groups data by different categories. The data is grouped based on one or several variables and analysis is performed on the individual groups."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['ADDRTYPE'].unique() #ADDRTYPE\tCOLLISIONTYPE"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# grouping results\n","df_gptest = df[['hourofday','ADDRTYPE','SEVERITYCODE']]\n","grouped_test1 = df_gptest.groupby(['hourofday','ADDRTYPE'],as_index=False).mean()\n","grouped_test1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# This grouped data is much easier to visualize when it is made into a pivot table\n","grouped_pivot = grouped_test1.pivot(index='ADDRTYPE',columns='hourofday')\n","grouped_pivot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#use a heat map to visualize the relationship between Body Style vs Price.\n","fig, ax = plt.subplots()\n","im = ax.pcolor(grouped_pivot, cmap='RdBu')\n","\n","#label names\n","row_labels = grouped_pivot.columns.levels[1]\n","col_labels = grouped_pivot.index\n","\n","#move ticks and labels to the center\n","ax.set_xticks(np.arange(grouped_pivot.shape[1]) + 0.5, minor=False)\n","ax.set_yticks(np.arange(grouped_pivot.shape[0]) + 0.5, minor=False)\n","\n","#insert labels\n","ax.set_xticklabels(row_labels, minor=False)\n","ax.set_yticklabels(col_labels, minor=False)\n","\n","#rotate label if too long\n","plt.xticks(rotation=90)\n","\n","fig.colorbar(im)\n","plt.show()"]},{"source":["#### Correlation and Causation\n","\n","It is important to know the difference between these two and that correlation does not imply causation. Determining correlation is much simpler the determining causation as causation may require independent experimentation."],"cell_type":"markdown","metadata":{}},{"source":["#### ANOVA: Analysis of Variance\n","\n","test whether there are significant differences between the means of two or more groups. ANOVA returns two parameters:"],"cell_type":"markdown","metadata":{}},{"source":["## Map"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Folium Map\n","import folium\n","from folium import plugins\n","\n","# only show the injury record, not property collision\n","df_map_injury = df_map[df_map['SEVERITYCODE']==2]\n","# Make reduced df by selecting every 50th record\n","reduced_df = df_map_injury.iloc [0::20, 0:]\n","\n","#Folium Map\n","# let's start again with a clean copy of the map of San Francisco\n","seattle_map = folium.Map(location=[47.61536892, -122.3302243], zoom_start=10)\n","\n","# instantiate a mark cluster object for the incidents in the dataframe\n","incidents = plugins.MarkerCluster().add_to(seattle_map)\n","\n","# loop through the dataframe and add each data point to the mark cluster\n","for lat, lng, label, in zip(reduced_df.Y, reduced_df.X, reduced_df.SEVERITYCODE):\n","    folium.Marker(\n","    location=[lat, lng],\n","    icon=None,\n","    popup=label,\n","    ).add_to(incidents)\n","\n","seattle_map.add_child(incidents)\n","\n","# display map\n","seattle_map\n","#seattle_map.save(\"seattlemap.html\")\n","#webbrowser.open(\"seattlemap.html\")"]},{"source":["# Model Pre-processing:  Feature selection/extraction"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y = df[\"SEVERITYCODE\"]"]},{"source":["## Feature selection"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# convert these features to numerical values\n","Feature = df[['ADDRTYPE', 'JUNCTIONTYPE', 'INATTENTIONIND', 'UNDERINFL', 'WEATHER', 'ROADCOND',\n","       'LIGHTCOND', 'SPEEDING', 'RiskTime','weekend']]\n","X = Feature.values\n","X[0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['weekend'].value_counts()"]},{"source":["## Convert Categorical features to numerical values"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn import preprocessing\n","le_ADDRTYPE = preprocessing.LabelEncoder()\n","\n","le_ADDRTYPE.fit(['Intersection', 'Block', 'Alley'])\n","X[:,0] = le_ADDRTYPE.transform(X[:,0]) \n","\n","le_JUNCTIONTYPE = preprocessing.LabelEncoder()\n","X[:,1] = le_JUNCTIONTYPE.fit([ 'Mid-Block (not related to intersection)', 'RampDriveway',\n","       'Mid-Block (but intersection related)','At-Intersection']).transform(X[:,1])\n","\n","le_INATTENTIONIND = preprocessing.LabelEncoder()\n","X[:,2] = le_INATTENTIONIND.fit(['N', 'Y']).transform(X[:,2]) \n","\n","le_UNDERINFL = preprocessing.LabelEncoder()\n","X[:,3] = le_UNDERINFL.fit(['N', 'Y']).transform(X[:,3]) \n","\n","le_WEATHER = preprocessing.LabelEncoder()\n","X[:,4] = le_WEATHER.fit(['Overcast', 'RainSnow', 'Clear', 'Unknown']).transform(X[:,4]) \n","\n","le_ROADCOND = preprocessing.LabelEncoder()\n","X[:,5] = le_ROADCOND.fit(['Wet', 'Dry', 'Unknown', 'IceOilWaterSnow']).transform(X[:,5]) \n","\n","le_LIGHTCOND = preprocessing.LabelEncoder()\n","X[:,6] = le_LIGHTCOND.fit(['Daylight', 'Dark-With-Light', 'Dark-No-Light', 'Unknown','DuskDawn']).transform(X[:,6]) \n","\n","le_SPEEDING = preprocessing.LabelEncoder()\n","X[:,7] = le_SPEEDING.fit(['N', 'Y']).transform(X[:,7]) \n","\n","le_RiskTime = preprocessing.LabelEncoder()\n","X[:,8] = le_RiskTime.fit(['Medium', 'Low', 'High']).transform(X[:,8]) \n","\n","le_weekend = preprocessing.LabelEncoder()\n","X[:,9] = le_weekend.fit([0, 1]).transform(X[:,9]) \n","\n","X[0:5]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","#Test/Train split\n","X_train_raw, X_test, y_train_raw, y_test = train_test_split(X, y, test_size=0.4, random_state=4)\n","print ('Train set:', X_train_raw.shape,  y_train_raw.shape)\n","print ('Test set:', X_test.shape,  y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["# Balance the Data using SMOTE mathod\n","!pip3 install -U imbalanced-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["# Balance the Data using SMOTE mathod, system will generate more data to balance the unbalanced data\n","import imblearn\n","from imblearn.over_sampling import SMOTE\n","\n","os = SMOTE (random_state=0)\n","X_train, y_train = os.fit_sample(X_train_raw, y_train_raw)\n","print ('Train set:', X_train.shape,  y_train.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["print(\"----------Sample % before SMOTE--------------\")\n","print(y_train_raw.value_counts()/len(y_train_raw))\n","print(\"----------Sample % After SMOTE --------------\")\n","print(pd.Series(y_train).value_counts()/len(y_train))"]},{"source":["# Classification "],"cell_type":"markdown","metadata":{}},{"source":["## K Nearest Neighbor(KNN)\n"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn import metrics\n","\n","# Find the best K between 1 an 10\n","grid_params = {'n_neighbors': [i for i in range(1, 10)]}\n","grid = GridSearchCV(KNeighborsClassifier(),grid_params,cv = 5)\n","grid_results = grid.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# visual the result of finding best K\n","sns.set_style(\"whitegrid\")\n","sns.lineplot(grid_params['n_neighbors'], grid_results.cv_results_['mean_test_score'], palette=\"hls\", linewidth=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["print(\"The best n_neighbors was  : \", grid_results.best_params_['n_neighbors'])\n","print(\"The best accuracy was with:\", grid_results.best_score_.round(2))"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["# using the best K (5) to model\n","neigh = KNeighborsClassifier(n_neighbors = grid_results.best_params_.get('n_neighbors')).fit(X_train,y_train)\n","yhat_train = neigh.predict(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["print(\"KNN Accuracy     : {:.2f}\".format(metrics.accuracy_score(y_train, yhat_train)))\n","print(\"KNN Jaccard index: {:.2f}\".format(metrics.jaccard_score(y_train, yhat_train)))\n","print(\"KNN F1-score     : {:.2f}\".format(metrics.f1_score(y_train, yhat_train, average='weighted')))"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["# Train data result: Confusion Matrix and report\n","import sklearn\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import plot_confusion_matrix\n","\n","print(confusion_matrix(y_train, yhat_train))\n","print(classification_report(y_train, yhat_train))\n","\n","plot_confusion_matrix(neigh, X_train, y_train, include_values=True)\n","plt.show()  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["# Test dataset result\n","yhat_test = neigh.predict(X_test)\n","\n","print(confusion_matrix(y_test, yhat_test))\n","print(classification_report(y_test, yhat_test))\n","\n","plot_confusion_matrix(neigh, X_test, y_test, include_values=True)\n","plt.show() "]},{"source":["## Decision Tree"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn import tree\n","import graphviz\n","import matplotlib.image as mpimg\n","\n","# Find the best para\n","tree_grid_params = {'criterion': ['entropy'], 'max_depth': [i for i in range(3,30)]}\n","tree_grid = GridSearchCV(tree.DecisionTreeClassifier(), tree_grid_params, cv = 3)\n","tree_grid_results = tree_grid.fit(X_train, y_train)\n","\n","#plot the result of finding best para\n","sns.set_style(\"whitegrid\")\n","sns.lineplot(tree_grid_params['max_depth'], tree_grid_results.cv_results_['mean_test_score'], palette=\"hls\", linewidth=2)\n","print(\"The best tree_depth was: \",tree_grid_results.best_params_[\"max_depth\"])\n","print(\"The best accuracy was  : \",tree_grid_results.best_score_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# using the best result\n","carTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = tree_grid_results.best_params_.get('max_depth'))\n","carTree.fit(X_train,y_train)\n","y_predTree = carTree.predict(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["print(\"loanTree Jaccard index: {:.2f}\".format(metrics.jaccard_score(y_train, y_predTree)))\n","print(\"loanTree F1-score     : {:.2f}\".format(metrics.f1_score(y_train, y_predTree, average='weighted')))"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["# # Confusion Matrix and report - Train data\n","import sklearn\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import plot_confusion_matrix\n","\n","print(confusion_matrix(y_train, y_predTree))\n","print(classification_report(y_train, y_predTree))\n","\n","plot_confusion_matrix(carTree, X_train, y_train, include_values=True)\n","plt.show()  "]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["# # Confusion Matrix and report - Train data\n","y_test_predTree = carTree.predict(X_test)\n","print(confusion_matrix(y_test, y_test_predTree))\n","print(classification_report(y_test, y_test_predTree))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Visualize the result\n","plot_confusion_matrix(carTree, X_test, y_test, include_values=True)\n","plt.show() "]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["# Visualize Decision Tree\n","#!pip3 install pydot\n","#!pip3 install graphviz\n","import pandas as pd\n","import numpy as np\n","from sklearn import tree\n","import pydot\n","from IPython.display import Image\n","from sklearn.externals.six import StringIO\n","\n","X = df[['ADDRTYPE', 'JUNCTIONTYPE', 'INATTENTIONIND', 'UNDERINFL', 'WEATHER', 'ROADCOND',\n","       'LIGHTCOND', 'SPEEDING', 'RiskTime','weekend']]\n","\n","from sklearn import tree\n","plt.figure(figsize=(40,20))  \n","_ = tree.plot_tree(carTree, feature_names = X.columns, \n","             filled=True, fontsize=6, rounded = True)\n","plt.show()\n","plt.savefig('filename.png')\n"]},{"source":["## Logistic Regression"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix\n","\n","# find the best para\n","grid_params = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]} # l1 lasso l2 ridge\n","LR_grid = GridSearchCV(LogisticRegression(),grid_params,cv=3)\n","LR_grid.fit(X_train,y_train)\n","\n","print(\"The best parameter was: \",LR_grid.best_params_) # {'C': 0.001, 'penalty': 'l2'}\n","print(\"The best accuracy was : \",LR_grid.best_score_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Using the best parameter to model\n","LR = LogisticRegression(C=0.01, solver='liblinear',penalty='l2').fit(X,y)\n","yhat_train_LR = LR.predict(X_train)\n","yhat_train_LR_prob = LR.predict_proba(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["print(\"LR Jaccard index: {:.2f}\".format(metrics.jaccard_score(y_train, yhat_train_LR)))\n","print(\"LR F1-score     : {:.2f}\".format(metrics.f1_score(y_train, yhat_train_LR, average='weighted')))\n","print(\"LR Log Loss     : {:.2f}\".format(metrics.log_loss(y_train, yhat_train_LR_prob)))"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["# # Confusion Matrix and report - Train data\n","import sklearn\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import plot_confusion_matrix\n","\n","print(confusion_matrix(y_train, yhat_train_LR))\n","print(classification_report(y_train, yhat_train_LR))\n","\n","plot_confusion_matrix(LR, X_train, y_train, include_values=True)\n","plt.show()  "]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["# # Confusion Matrix and report - Train data\n","yhat_test_LR = LR.predict(X_test)\n","\n","print(confusion_matrix(y_test, yhat_test_LR))\n","print(classification_report(y_test, yhat_test_LR))\n","\n","plot_confusion_matrix(LR, X_test, y_test, include_values=True)\n","plt.show()  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"name":"Python 3.8.5 64-bit","display_name":"Python 3.8.5 64-bit","metadata":{"interpreter":{"hash":"082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"}}},"language_info":{"name":"python","version":"3.8.5-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"state":{},"version":"1.1.2"}},"nbformat":4,"nbformat_minor":4}